{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tarfile\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torch.distributions.normal import Normal\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR VAE\n",
    "\n",
    "def criterionVAE(x, x_hat, z, mu, log_std):\n",
    "    RE = F.mse_loss(x, x_hat, reduction='sum')\n",
    "    \n",
    "    std = log_std.exp()\n",
    "    KL = -(z.shape[0]/2) \n",
    "    #KL -= (z.shape[0]/2)*torch.log(1/1)\n",
    "    KL -= (1/2)*torch.sum(torch.log(std.pow(2)))\n",
    "    KL += (1/2)*torch.sum(mu.pow(2) + std.pow(2))\n",
    "\n",
    "    return (RE + KL) / z.shape[0]\n",
    "\n",
    "\n",
    "def trainVAE(x):\n",
    "    model.zero_grad()\n",
    "    mu, log_std = model.encoder(x)\n",
    "    z = model.reparameterize(mu, log_std)\n",
    "    x_hat = model.decoder(z)\n",
    "    loss = criterionVAE(x, x_hat, z, mu, log_std)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR GAN\n",
    "\n",
    "def D_train(x):\n",
    "    D.zero_grad()\n",
    "\n",
    "    x_real, y_real = x.view(-1, mnist_dim).to(device), torch.ones(x.shape[0], 1).to(device)\n",
    "    D_output = D(x_real)\n",
    "    D_real_loss = criterionGAN(D_output, y_real)\n",
    "\n",
    "    z = torch.randn(bs, z_dim).to(device)\n",
    "    x_fake, y_fake = G(z), torch.zeros(bs, 1).to(device)\n",
    "    D_output = D(x_fake)\n",
    "    D_fake_loss = criterionGAN(D_output, y_fake)\n",
    "\n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "    D_loss.backward()\n",
    "    D_optimizer.step()\n",
    "        \n",
    "    return  D_loss.data.item()\n",
    "\n",
    "\n",
    "def G_train(x):\n",
    "    G.zero_grad()\n",
    "\n",
    "    z = torch.randn(bs, z_dim).to(device)\n",
    "    y = torch.ones(bs, 1).to(device)\n",
    "\n",
    "    G_output = G(z)\n",
    "    D_output = D(G_output)\n",
    "    G_loss = criterionGAN(D_output, y)\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_optimizer.step()\n",
    "        \n",
    "    return G_loss.data.item()\n",
    "\n",
    "\n",
    "criterionGAN = nn.BCELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "mnist_loader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "\n",
    "mnist_dim = trainset.train_data.size(1) * trainset.train_data.size(2)\n",
    "\n",
    "del trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, D, M):\n",
    "        super(VAE, self).__init__()\n",
    "        self.D = D\n",
    "        self.M = M\n",
    "        \n",
    "        self.enc1 = nn.Linear(self.D, 1024)\n",
    "        self.enc2 = nn.Linear(self.enc1.out_features, self.enc1.out_features//2)\n",
    "        self.enc3 = nn.Linear(self.enc2.out_features, self.enc2.out_features//2)\n",
    "        self.enc4 = nn.Linear(self.enc3.out_features, self.M*2)\n",
    "        \n",
    "        self.dec1 = nn.Linear(self.M, 256)\n",
    "        self.dec2 = nn.Linear(self.dec1.out_features, self.dec1.out_features*2)\n",
    "        self.dec3 = nn.Linear(self.dec2.out_features, self.dec2.out_features*2)\n",
    "        self.dec4 = nn.Linear(self.dec3.out_features, self.D)\n",
    "        \n",
    "        \n",
    "    def encoder(self, x):\n",
    "        x = F.leaky_relu(self.enc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.enc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.enc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = self.enc4(x).view(-1, 2, self.M)\n",
    "        return x[:, 0, :], x[:, 1, :]\n",
    "\n",
    "    \n",
    "    def reparameterize(self, mu, log_std):\n",
    "        std = log_std.exp()\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps*std)  # z\n",
    "    \n",
    "    \n",
    "    def decoder(self, z):\n",
    "        x = F.leaky_relu(self.dec1(z), 0.2)\n",
    "        x = F.leaky_relu(self.dec2(x), 0.2)\n",
    "        x = F.leaky_relu(self.dec3(x), 0.2)\n",
    "        return torch.tanh(self.dec4(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(mnist_dim, 20)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0002)\n",
    "\n",
    "n_weights = 0\n",
    "for parameter in model.parameters():\n",
    "    n_weights += torch.tensor(parameter.shape).sum()\n",
    "\n",
    "print(f'There are {n_weights} weights in the VAE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 50\n",
    "lossesVAE = []\n",
    "for epoch in range(1, n_epoch+1):           \n",
    "    epochloss = 0\n",
    "    for batch_idx, (x, _) in enumerate(mnist_loader):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        batchloss = trainVAE(x.to(device))\n",
    "        epochloss += batchloss\n",
    "        lossesVAE.append(batchloss)\n",
    "    \n",
    "    mu, log_std = model.encoder(x[:8].to(device))\n",
    "    z = model.reparameterize(mu, log_std)\n",
    "    x_hat = model.decoder(z)\n",
    "    \n",
    "    save_image(torch.cat((x[:8].view(8, 1, 28, 28), \n",
    "                           x_hat.view(8, 1, 28, 28).cpu())), \n",
    "                         f\"MNIST/VAE_outputs/output_{epoch}.png\", nrow=8)\n",
    "\n",
    "    print('[%d/%d]: loss: %.3f' % (\n",
    "            (epoch), n_epoch, epochloss/len(mnist_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'MNIST/VAE')\n",
    "\n",
    "model = torch.load('MNIST/VAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for j in range(10):\n",
    "        z = np.random.randn(20, 2)\n",
    "        steps = (z[:, 0] - z[:, 1]) / 8\n",
    "\n",
    "        z_interpolate = np.zeros((10, 20))\n",
    "        z_interpolate[ 0, :] = z[:, 0]\n",
    "        z_interpolate[-1, :] = z[:, 1]\n",
    "\n",
    "        for i in range(z_interpolate.shape[0]):\n",
    "            if i != 0 or i != 9:\n",
    "                z_interpolate[i, :] = z_interpolate[0, :] - steps*i\n",
    "\n",
    "        z_interpolate = torch.tensor(z_interpolate, dtype=torch.float).to(device)\n",
    "\n",
    "        interp_VAE = model.decoder(z_interpolate).view(10, 1, 28, 28).cpu()\n",
    "        \n",
    "        if \"result_\" in dir():\n",
    "            result_ = torch.cat((result_, interp_VAE))\n",
    "        else:\n",
    "            result_ = interp_VAE\n",
    "        \n",
    "    save_image(result_, f\"MNIST/VAE_outputs/interpolation.png\", nrow=10)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    z_test = torch.randn(64, 20).to(device)\n",
    "    test_VAE = model.decoder(z_test)\n",
    "    save_image(test_VAE.view(64, 1, 28, 28).cpu(),\n",
    "               f\"MNIST/VAE_outputs/test.png\", nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossesVAE)\n",
    "plt.grid()\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('MNIST/VAE_MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, g_input_dim, g_output_dim):\n",
    "        super(Generator, self).__init__()       \n",
    "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
    "    \n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        return torch.tanh(self.fc4(x))\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d_input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        return torch.sigmoid(self.fc4(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "\n",
    "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
    "D = Discriminator(mnist_dim).to(device)\n",
    "\n",
    "lr = 0.0002 \n",
    "G_optimizer = optim.Adam(G.parameters(), lr = lr)\n",
    "D_optimizer = optim.Adam(D.parameters(), lr = lr)\n",
    "\n",
    "n_weights = 0\n",
    "for parameter in G.parameters():\n",
    "    n_weights += torch.tensor(parameter.shape).sum()\n",
    "\n",
    "print(f'There are {n_weights} weights in the GAN Generator.')\n",
    "\n",
    "n_weights = 0\n",
    "for parameter in D.parameters():\n",
    "    n_weights += torch.tensor(parameter.shape).sum()\n",
    "\n",
    "print(f'There are {n_weights} weights in the GAN Discriminator.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 200\n",
    "lossesGAN_D = []\n",
    "lossesGAN_G = []\n",
    "\n",
    "for epoch in range(1, n_epoch+1):           \n",
    "    D_epochloss, G_epochloss = 0, 0\n",
    "    for batch_idx, (x, _) in enumerate(mnist_loader):\n",
    "        D_loss, G_loss = D_train(x), G_train(x)\n",
    "        D_epochloss += D_loss\n",
    "        G_epochloss += G_loss\n",
    "        lossesGAN_D.append(D_loss)\n",
    "        lossesGAN_G.append(G_loss)\n",
    "    \n",
    "    z = torch.randn(16, z_dim).to(device)\n",
    "    G_output = G(z)\n",
    "    save_image(G_output.reshape(16, 1, 28, 28).cpu(), f\"MNIST/GAN_outputs/output_{epoch}.png\", nrow=8)\n",
    "\n",
    "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
    "            (epoch), n_epoch, D_epochloss/len(mnist_loader), G_epochloss/len(mnist_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(G, 'MNIST/Generator')\n",
    "#torch.save(D, 'MNIST/Discriminator')\n",
    "\n",
    "G = torch.load('MNIST/Generator')\n",
    "D = torch.load('MNIST/Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z_test = torch.randn(64, 100).to(device)\n",
    "    test_GAN = G(z_test)\n",
    "    save_image(test_GAN.view(64, 1, 28, 28).cpu(), \n",
    "               f\"MNIST/GAN_outputs/test.png\", nrow=8)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for j in range(10):\n",
    "        z = np.random.randn(100, 2)\n",
    "        steps = (z[:, 0] - z[:, 1]) / 8\n",
    "\n",
    "        z_interpolate = np.zeros((10, 100))\n",
    "        z_interpolate[ 0, :] = z[:, 0]\n",
    "        z_interpolate[-1, :] = z[:, 1]\n",
    "\n",
    "        for i in range(z_interpolate.shape[0]):\n",
    "            if i != 0 or i != 9:\n",
    "                z_interpolate[i, :] = z_interpolate[0, :] - steps*i\n",
    "\n",
    "        z_interpolate = torch.tensor(z_interpolate, dtype=torch.float).to(device)\n",
    "\n",
    "        interp_GAN = G(z_interpolate).view(10, 1, 28, 28).cpu()\n",
    "        \n",
    "        if \"result__\" in dir():\n",
    "            result__ = torch.cat((result__, interp_GAN))\n",
    "        else:\n",
    "            result__ = interp_GAN\n",
    "        \n",
    "    save_image(result__, f\"MNIST/GAN_outputs/interpolation.png\", nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossesGAN_D, label='Discriminator')\n",
    "plt.plot(lossesGAN_G, label='Generator')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('MNIST/GAN_MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT IMAGENETTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 48\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.CenterCrop(160)])#,\n",
    "    #transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=\"data/imagenette2-160/train/\", \n",
    "                                                            transform=transform)\n",
    "\n",
    "imag_loader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "imag_dim = torch.tensor(trainset[0][0].shape)\n",
    "\n",
    "del trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE IMAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, D, M):\n",
    "        super(VAE, self).__init__()\n",
    "        self.D = D\n",
    "        self.M = M\n",
    "        \n",
    "        self.enc1 = nn.Conv2d(3, 16, kernel_size=3)\n",
    "        self.enc2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.enc3 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.enc4 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.enc5 = nn.Linear(128*8*8, self.M*2)\n",
    "        \n",
    "        self.dec1 = nn.Linear(self.M, 256*8*8)\n",
    "        self.dec2 = nn.ConvTranspose2d(256, 128, 4, stride=2)\n",
    "        self.norm2 = nn.BatchNorm2d(128)\n",
    "        self.dec3 = nn.ConvTranspose2d(128, 64, 4, stride=2)\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        self.dec4 = nn.ConvTranspose2d(64, 32, 4, stride=2)\n",
    "        self.norm4 = nn.BatchNorm2d(32)\n",
    "        self.dec5 = nn.ConvTranspose2d(32, 16, 4, stride=2)\n",
    "        self.norm5 = nn.BatchNorm2d(16)\n",
    "        self.dec6 = nn.ConvTranspose2d(16, 8, 3)\n",
    "        self.norm6 = nn.BatchNorm2d(8)\n",
    "        self.dec7 = nn.ConvTranspose2d(8, 3, 3)\n",
    "        \n",
    "        \n",
    "    def encoder(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.enc1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.enc2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.enc3(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.enc4(x)), 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.enc5(x).view(-1, 2, self.M)\n",
    "        return x[:, 0, :], x[:, 1, :]\n",
    "\n",
    "    \n",
    "    def reparameterize(self, mu, log_std):\n",
    "        std = log_std.exp()\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps*std)  # z\n",
    "    \n",
    "    \n",
    "    def decoder(self, z):\n",
    "        x = F.leaky_relu(self.dec1(z)).view(-1, 256, 8, 8)\n",
    "        x = self.norm2(F.leaky_relu(self.dec2(x)))\n",
    "        x = self.norm3(F.leaky_relu(self.dec3(x)))\n",
    "        x = self.norm4(F.leaky_relu(self.dec4(x)))\n",
    "        x = self.norm5(F.leaky_relu(self.dec5(x)))\n",
    "        x = self.norm6(F.leaky_relu(self.dec6(x)))\n",
    "        x = self.dec7(x)\n",
    "        x = F.interpolate(x, size=(160, 160), mode='nearest')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(imag_dim, 100)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0002)\n",
    "\n",
    "n_weights = 0\n",
    "for parameter in model.parameters():\n",
    "    n_weights += torch.tensor(parameter.shape).sum()\n",
    "\n",
    "print(f'There are {n_weights} weights in the VAE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "losses = []\n",
    "for epoch in range(1, n_epoch+1):           \n",
    "    epochloss = 0\n",
    "    for batch_idx, (x, _) in enumerate(imag_loader):\n",
    "        loss = trainVAE(x.to(device))\n",
    "        epochloss += loss\n",
    "        losses.append(loss)\n",
    "        print (\"\\r Batch: [{}/{}]\".format(batch_idx+1, len(imag_loader)), end=\"\")\n",
    "    \n",
    "    mu, logvar = model.encoder(x[:8].to(device))\n",
    "    z = model.reparameterize(mu, logvar)\n",
    "    x_hat = model.decoder(z)\n",
    "    save_image(torch.cat((x[:8].view(8, 3, 160, 160), \n",
    "                          x_hat.view(8, 3, 160, 160).cpu())), \n",
    "               f\"IMAG/VAE_outputs/output_{epoch}.png\", nrow=8)\n",
    "\n",
    "    print('[%d/%d]: loss: %.3f' % (\n",
    "            (epoch), n_epoch, epochloss/len(imag_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'IMAG/VAE')\n",
    "\n",
    "model = torch.load('IMAG/VAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z_test = torch.randn(64, 100).to(device)\n",
    "    test_VAE = model.decoder(z_test)\n",
    "    save_image(test_VAE.view(64, 3, 160, 160).cpu(),\n",
    "               f\"IMAG/VAE_outputs/test.png\", nrow=8)\n",
    "    \n",
    "\n",
    "with torch.no_grad():\n",
    "    for j in range(10):\n",
    "        z = np.random.randn(100, 2)\n",
    "        steps = (z[:, 0] - z[:, 1]) / 8\n",
    "\n",
    "        z_interpolate = np.zeros((10, 100))\n",
    "        z_interpolate[ 0, :] = z[:, 0]\n",
    "        z_interpolate[-1, :] = z[:, 1]\n",
    "\n",
    "        for i in range(z_interpolate.shape[0]):\n",
    "            if i != 0 or i != 9:\n",
    "                z_interpolate[i, :] = z_interpolate[0, :] - steps*i\n",
    "\n",
    "        z_interpolate = torch.tensor(z_interpolate, dtype=torch.float).to(device)\n",
    "\n",
    "        interp_VAE = model.decoder(z_interpolate).view(10, 3, 160, 160).cpu()\n",
    "        \n",
    "        if \"result_\" in dir():\n",
    "            result_ = torch.cat((result_, interp_VAE))\n",
    "        else:\n",
    "            result_ = interp_VAE\n",
    "        \n",
    "    save_image(result_, f\"IMAG/VAE_outputs/interpolation.png\", nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_VAE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result_\n",
    "\n",
    "\n",
    "for batch_idx, (x, _) in enumerate(imag_loader):\n",
    "    break\n",
    "\n",
    "with torch.no_grad():\n",
    "    for j in range(10):\n",
    "        instances = np.random.choice(x.shape[0], 2, replace=False)\n",
    "        mu_start, log_std_start = model.encoder(x[instances[0], :, :, :].unsqueeze(0).to(device))\n",
    "        mu_end, log_std_end = model.encoder(x[instances[1], :, :, :].unsqueeze(0).to(device))\n",
    "        z_start = model.reparameterize(mu_start, log_std_start).cpu()\n",
    "        z_end = model.reparameterize(mu_end, log_std_end).cpu()\n",
    "        \n",
    "        steps = (z_start - z_end) / 8\n",
    "\n",
    "        z_interpolate = np.zeros((10, 100))\n",
    "        z_interpolate[ 0, :] = z_start\n",
    "        z_interpolate[-1, :] = z_end\n",
    "\n",
    "        for i in range(z_interpolate.shape[0]):\n",
    "            if i != 0 or i != 9:\n",
    "                z_interpolate[i, :] = z_interpolate[0, :] - np.array(steps.squeeze()*i)\n",
    "\n",
    "        z_interpolate = torch.tensor(z_interpolate, dtype=torch.float).to(device)\n",
    "\n",
    "        interp_VAE = model.decoder(z_interpolate).view(10, 3, 160, 160).cpu()\n",
    "        interp_VAE = torch.cat((x[instances[0], :, :, :].unsqueeze(0), interp_VAE, x[instances[1], :, :, :].unsqueeze(0)))\n",
    "        \n",
    "        if \"result_\" in dir():\n",
    "            result_ = torch.cat((result_, interp_VAE))\n",
    "        else:\n",
    "            result_ = interp_VAE\n",
    "        \n",
    "    save_image(result_, f\"IMAG/VAE_outputs/interpolation2.png\", nrow=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_p1.extend(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_p1)\n",
    "plt.grid()\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('IMAG/VAE_IMAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_p1 = losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN IMAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_train(x):\n",
    "    D.zero_grad()\n",
    "\n",
    "    x_real, y_real = x.to(device), torch.tensor([0.95]*x.shape[0]).unsqueeze(1).to(device)  #torch.ones(x.shape[0], 1).to(device) #\n",
    "    D_output = D(x_real)\n",
    "    D_real_loss = criterionGAN(D_output, y_real)\n",
    "\n",
    "    z = torch.randn(x.shape[0], z_dim).to(device)\n",
    "    x_fake, y_fake = G(z), torch.zeros(x.shape[0], 1).to(device)\n",
    "    D_output = D(x_fake)\n",
    "    D_fake_loss = criterionGAN(D_output, y_fake)\n",
    "\n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "    D_loss.backward()\n",
    "    D_optimizer.step()\n",
    "        \n",
    "    return  D_loss.data.item()\n",
    "\n",
    "#def G_train(x, real):\n",
    "#    G.zero_grad()\n",
    "#\n",
    "#    z = torch.randn(x.shape[0], z_dim).to(device)\n",
    "#    y = torch.ones(x.shape[0], 1).to(device)\n",
    "#\n",
    "#    G_output = G(z)\n",
    "#    D_output = D(G_output, gen=True)\n",
    "#    \n",
    "#    D_output, real = torch.mean(D_output, 0), torch.mean(real, 0)\n",
    "#    G_loss = F.mse_loss(D_output, real)\n",
    "#\n",
    "#    G_loss.backward()\n",
    "#    G_optimizer.step()\n",
    "#        \n",
    "#    return G_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, g_input_dim, g_output_dim):\n",
    "        super(Generator, self).__init__()       \n",
    "        #self.gen1 = nn.Linear(g_input_dim, 256*8*8)\n",
    "        self.gen2 = nn.ConvTranspose2d(256, 128, 4, stride=2)\n",
    "        self.norm2 = nn.BatchNorm2d(128)\n",
    "        self.gen3 = nn.ConvTranspose2d(128, 64, 4, stride=2)\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        self.gen4 = nn.ConvTranspose2d(64, 32, 4, stride=2)\n",
    "        self.norm4 = nn.BatchNorm2d(32)\n",
    "        self.gen5 = nn.ConvTranspose2d(32, 16, 4, stride=2)\n",
    "        self.norm5 = nn.BatchNorm2d(16)\n",
    "        self.gen6 = nn.ConvTranspose2d(16, 8, 3)\n",
    "        self.norm6 = nn.BatchNorm2d(8)\n",
    "        self.gen7 = nn.ConvTranspose2d(8, 3, 3)\n",
    "    \n",
    "\n",
    "    def forward(self, z): \n",
    "        #x = F.leaky_relu(self.gen1(z)).view(-1, 256, 8, 8)\n",
    "        x = z.view(-1, 256, 8, 8)\n",
    "        x = self.norm2(F.leaky_relu(self.gen2(x)))\n",
    "        x = self.norm3(F.leaky_relu(self.gen3(x)))\n",
    "        x = self.norm4(F.leaky_relu(self.gen4(x)))\n",
    "        x = self.norm5(F.leaky_relu(self.gen5(x)))\n",
    "        x = self.norm6(F.leaky_relu(self.gen6(x)))\n",
    "        x = self.gen7(x)\n",
    "        x = F.interpolate(x, size=(160, 160), mode='nearest')\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d_input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dis1 = nn.Conv2d(3, 16, kernel_size=3)\n",
    "        self.dis2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.dis3 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dis4 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.dis5 = nn.Linear(128*8*8, 1)\n",
    "    \n",
    "\n",
    "    def forward(self, x, gen=False):\n",
    "        x = F.max_pool2d(F.leaky_relu(self.dis1(x)), 2)\n",
    "        x = F.max_pool2d(F.leaky_relu(self.dis2(x)), 2)\n",
    "        x = F.max_pool2d(F.leaky_relu(self.dis3(x)), 2)\n",
    "        x = F.max_pool2d(F.leaky_relu(self.dis4(x)), 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return torch.sigmoid(self.dis5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 256*8*8\n",
    "\n",
    "G = Generator(g_input_dim = z_dim, g_output_dim = imag_dim).to(device)\n",
    "D = Discriminator(imag_dim).to(device)\n",
    "\n",
    "lr_G = 0.00001\n",
    "lr_D = 0.00005\n",
    "G_optimizer = optim.Adam(G.parameters(), lr = lr_G)\n",
    "D_optimizer = optim.Adam(D.parameters(), lr = lr_D)\n",
    "\n",
    "n_weights = 0\n",
    "for parameter in G.parameters():\n",
    "    n_weights += torch.tensor(parameter.shape).sum()\n",
    "\n",
    "print(f'There are {n_weights} weights in the GAN Generator.')\n",
    "\n",
    "n_weights = 0\n",
    "for parameter in D.parameters():\n",
    "    n_weights += torch.tensor(parameter.shape).sum()\n",
    "\n",
    "print(f'There are {n_weights} weights in the GAN Discriminator.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 200\n",
    "lossesGAN_D = []\n",
    "lossesGAN_G = []\n",
    "\n",
    "for epoch in range(1, n_epoch+1):           \n",
    "    D_epochloss, G_epochloss = 0, 0\n",
    "    for batch_idx, (x, _) in enumerate(imag_loader):\n",
    "        D_loss = D_train(x)\n",
    "        G_loss = G_train(x)\n",
    "        D_epochloss += D_loss\n",
    "        G_epochloss += G_loss\n",
    "        lossesGAN_D.append(D_loss)\n",
    "        lossesGAN_G.append(G_loss)\n",
    "        print (\"\\r Batch: [{}/{}]\".format(batch_idx+1, len(imag_loader)), end=\"\")\n",
    "    \n",
    "    z = torch.randn(16, z_dim).to(device)\n",
    "    G_output = G(z)\n",
    "    save_image(G_output.reshape(16, 3, 160, 160).cpu(), f\"IMAG/GAN_outputs/output_{epoch}.png\", nrow=8)\n",
    "\n",
    "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
    "            (epoch), n_epoch, D_epochloss/len(imag_loader), G_epochloss/len(imag_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G, 'IMAG/Generator')\n",
    "torch.save(D, 'IMAG/Discriminator')\n",
    "\n",
    "#G = torch.load('IMAG/Generator')\n",
    "#D = torch.load('IMAG/Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z_test = torch.randn(64, z_dim).to(device)\n",
    "    test_GAN = G(z_test)\n",
    "    save_image(test_GAN.view(64, 3, 160, 160).cpu(), \n",
    "               f\"IMAG/GAN_outputs/test.png\", nrow=8)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for j in range(10):\n",
    "        z = np.random.randn(z_dim, 2)\n",
    "        steps = (z[:, 0] - z[:, 1]) / 8\n",
    "\n",
    "        z_interpolate = np.zeros((10, z_dim))\n",
    "        z_interpolate[ 0, :] = z[:, 0]\n",
    "        z_interpolate[-1, :] = z[:, 1]\n",
    "\n",
    "        for i in range(z_interpolate.shape[0]):\n",
    "            if i != 0 or i != 9:\n",
    "                z_interpolate[i, :] = z_interpolate[0, :] - steps*i\n",
    "\n",
    "        z_interpolate = torch.tensor(z_interpolate, dtype=torch.float).to(device)\n",
    "\n",
    "        interp_GAN = G(z_interpolate).view(10, 3, 160, 160)[:, :, :150, :150].cpu()\n",
    "        \n",
    "        if \"result__\" in dir():\n",
    "            result__ = torch.cat((result__, interp_GAN))\n",
    "        else:\n",
    "            result__ = interp_GAN\n",
    "        \n",
    "    save_image(result__, f\"IMAG/GAN_outputs/interpolation.png\", nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossesGAN_D, label='Discriminator')\n",
    "plt.plot(lossesGAN_G, label='Generator')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('IMAG/GAN_IMAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
