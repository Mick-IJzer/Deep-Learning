{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 264"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "\n",
    "trainvalset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset, valset = random_split(trainvalset, (50000, 10000))\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size*4,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size*4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "del trainset, valset, testset, trainvalset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 4, 3, 1, 1)\n",
    "        self.fc = nn.Linear(196, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.log_softmax(self.fc(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE A NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn(learning_rate=0.001):\n",
    "    net = Net()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return net, criterion, optimizer, device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(net, criterion, optimizer, device, epochs=5):\n",
    "\n",
    "    trainloss = []\n",
    "    valloss = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():   \n",
    "            l = 0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net(inputs)\n",
    "                l += criterion(outputs, labels)\n",
    "            trainloss.append(l/len(trainloader))\n",
    "            \n",
    "            if 'valloader' in dir():\n",
    "                l = 0\n",
    "                for i, data in enumerate(valloader, 0):\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                    outputs = net(inputs)\n",
    "                    l += criterion(outputs, labels)\n",
    "                valloss.append(l/len(valloader))  \n",
    "\n",
    "        print(f'EPOCH {epoch} ||')\n",
    "        print(f'\\tTRAIN: {trainloss[-1]} ||')\n",
    "                      \n",
    "        if 'valloader' in dir():\n",
    "            print(f'VAL: {valloss[-1]}')\n",
    "    \n",
    "    if 'valloader' in dir():\n",
    "        return trainloss, valloss\n",
    "    else:\n",
    "        return trainloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainresult = np.zeros((5, 15))\n",
    "valresult = np.zeros((5, 15))\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'ITERATION {i}')\n",
    "    net, criterion, optimizer, device = get_nn(learning_rate=0.005)\n",
    "    \n",
    "    trainloss, valloss = train(net, criterion, optimizer, device, epochs=15)\n",
    "    \n",
    "    trainresult[i] = trainloss\n",
    "    valresult[i] = valloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainresult2 = np.zeros((5, 15))\n",
    "valresult2 = np.zeros((5, 15))\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'ITERATION {i}')\n",
    "    net, criterion, optimizer, device = get_nn(learning_rate=0.001)\n",
    "    \n",
    "    trainloss, valloss = train(net, criterion, optimizer, device, epochs=15)\n",
    "    \n",
    "    trainresult[i] = trainloss\n",
    "    valresult[i] = valloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainresult3 = np.zeros((5, 15))\n",
    "valresult3 = np.zeros((5, 15))\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'ITERATION {i}')\n",
    "    net, criterion, optimizer, device = get_nn(learning_rate=0.0005)\n",
    "    \n",
    "    trainloss, valloss = train(net, criterion, optimizer, device, epochs=15)\n",
    "    \n",
    "    trainresult[i] = trainloss\n",
    "    valresult[i] = valloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### batch_size = 264, epochs = 15 #####\n",
    "\n",
    "Tr001 = np.array([[0.31474945, 0.20616516, 0.16378577, 0.14059964, 0.12357964,\n",
    "        0.11633095, 0.10979732, 0.09746411, 0.09751423, 0.09484882,\n",
    "        0.08633662, 0.08969431, 0.07861999, 0.07764962, 0.07902008],\n",
    "       [0.30680719, 0.21827681, 0.17699517, 0.15303053, 0.13843828,\n",
    "        0.12726253, 0.11727257, 0.11087177, 0.09999228, 0.09569807,\n",
    "        0.09076178, 0.08479355, 0.08525715, 0.07666479, 0.07749713],\n",
    "       [0.35068539, 0.23424751, 0.18476433, 0.16082682, 0.13696234,\n",
    "        0.1251477 , 0.11646529, 0.1109904 , 0.10379943, 0.09925129,\n",
    "        0.09304589, 0.09013391, 0.08281144, 0.0798907 , 0.07755478],\n",
    "       [0.43918547, 0.35232794, 0.30566332, 0.26773351, 0.21882735,\n",
    "        0.18889731, 0.15960349, 0.13807294, 0.12559281, 0.11705201,\n",
    "        0.10862825, 0.10354333, 0.10043009, 0.09534948, 0.09378526],\n",
    "       [0.3797583 , 0.27990371, 0.21176998, 0.16085176, 0.13076909,\n",
    "        0.11333763, 0.10199824, 0.09475242, 0.08620581, 0.07944243,\n",
    "        0.07450339, 0.07208928, 0.07061998, 0.06544194, 0.06160825]])\n",
    "Val001 = np.array([[0.33555955, 0.22373414, 0.17996122, 0.15734513, 0.13930024,\n",
    "        0.13315164, 0.12922783, 0.11691816, 0.11848835, 0.11626675,\n",
    "        0.10838666, 0.11573636, 0.10037606, 0.10144424, 0.10258617],\n",
    "       [0.32957476, 0.23399308, 0.18967538, 0.16703968, 0.15278476,\n",
    "        0.14267381, 0.12976891, 0.12577443, 0.11646718, 0.11120118,\n",
    "        0.11080954, 0.10309409, 0.10516   , 0.09699281, 0.09979912],\n",
    "       [0.38150427, 0.25652882, 0.2036778 , 0.18024346, 0.15516524,\n",
    "        0.14551182, 0.13858835, 0.13329849, 0.12443324, 0.12278662,\n",
    "        0.11786441, 0.11587249, 0.10735756, 0.10616543, 0.10267975],\n",
    "       [0.46268398, 0.37751541, 0.32522815, 0.28846043, 0.23507552,\n",
    "        0.20678769, 0.17327757, 0.15363982, 0.14362997, 0.13482277,\n",
    "        0.12823687, 0.12201282, 0.12001085, 0.11563803, 0.11680868],\n",
    "       [0.40373942, 0.29773885, 0.22769074, 0.1774826 , 0.14512101,\n",
    "        0.12798278, 0.1180227 , 0.11338321, 0.10481732, 0.09793787,\n",
    "        0.0937638 , 0.09392189, 0.09297325, 0.08732148, 0.08236488]])\n",
    "\n",
    "Tr005 = np.array([[0.25970817, 0.13165502, 0.10036188, 0.08979715, 0.08640306,\n",
    "        0.07377179, 0.06935777, 0.06419412, 0.06486621, 0.05846115,\n",
    "        0.05549387, 0.05594687, 0.05956002, 0.05067385, 0.04939837],\n",
    "       [0.2525284 , 0.15795287, 0.13500471, 0.11101262, 0.11214416,\n",
    "        0.09952364, 0.11118082, 0.09459263, 0.1034699 , 0.09916721,\n",
    "        0.0898119 , 0.08271453, 0.08261592, 0.08062547, 0.0807986 ],\n",
    "       [0.15459928, 0.11166361, 0.08678886, 0.10857711, 0.07431044,\n",
    "        0.07632867, 0.06157049, 0.05625704, 0.05701309, 0.05581316,\n",
    "        0.05359763, 0.0552398 , 0.0429869 , 0.04245877, 0.04247933],\n",
    "       [0.18069653, 0.11656231, 0.09150515, 0.08905601, 0.08199372,\n",
    "        0.07366855, 0.07797817, 0.0675329 , 0.07800166, 0.06270258,\n",
    "        0.05830973, 0.0591176 , 0.05984771, 0.05561578, 0.05534544],\n",
    "       [0.15283312, 0.1105253 , 0.08695336, 0.07273209, 0.06869704,\n",
    "        0.05919097, 0.05834841, 0.04996386, 0.05464161, 0.05541461,\n",
    "        0.05116295, 0.04775501, 0.04409708, 0.05527179, 0.0397753 ]])\n",
    "Val005 = np.array([[0.2757031 , 0.14913861, 0.11667317, 0.10698155, 0.10946987,\n",
    "        0.09324982, 0.09440534, 0.0866102 , 0.09049191, 0.08421662,\n",
    "        0.08717527, 0.08405174, 0.08869913, 0.08271113, 0.08021093],\n",
    "       [0.27275094, 0.18098673, 0.15854602, 0.13505512, 0.14066471,\n",
    "        0.12846607, 0.14617699, 0.12639982, 0.13972548, 0.12624553,\n",
    "        0.1228248 , 0.11594468, 0.11571361, 0.11537092, 0.11328931],\n",
    "       [0.16845165, 0.12939985, 0.1095859 , 0.13002427, 0.09923001,\n",
    "        0.10129827, 0.08868746, 0.0818914 , 0.08553504, 0.08721352,\n",
    "        0.08069589, 0.08657378, 0.08010703, 0.07615194, 0.07777274],\n",
    "       [0.19308451, 0.13635036, 0.11478456, 0.11746486, 0.11088292,\n",
    "        0.1023929 , 0.11174098, 0.09485953, 0.1077436 , 0.09503523,\n",
    "        0.09275126, 0.09268952, 0.09083874, 0.09044095, 0.0888153 ],\n",
    "       [0.17318176, 0.12557732, 0.10619797, 0.0968906 , 0.09284385,\n",
    "        0.08342581, 0.08737677, 0.07737605, 0.08639332, 0.08644295,\n",
    "        0.07997695, 0.08025545, 0.08115023, 0.0886455 , 0.07684118]])\n",
    "\n",
    "Tr0005 = np.array([[0.54404891, 0.3742241 , 0.32069299, 0.28194693, 0.24865218,\n",
    "        0.21242993, 0.18681173, 0.16628873, 0.15389916, 0.13868897,\n",
    "        0.12813438, 0.11933328, 0.11245593, 0.10683271, 0.10305476],\n",
    "       [0.54143584, 0.38072559, 0.32601529, 0.29482228, 0.26310447,\n",
    "        0.23966195, 0.21785745, 0.19808467, 0.1821164 , 0.16733468,\n",
    "        0.15699449, 0.14665689, 0.1383245 , 0.1395949 , 0.12660789],\n",
    "       [0.51873469, 0.36141801, 0.3065913 , 0.26510701, 0.229754  ,\n",
    "        0.20194298, 0.17383268, 0.15894645, 0.14309184, 0.12950891,\n",
    "        0.12211503, 0.11536687, 0.10715348, 0.10145348, 0.09773394],\n",
    "       [0.4536694 , 0.29532668, 0.24630019, 0.21774861, 0.19747753,\n",
    "        0.18121175, 0.17105512, 0.16151299, 0.15270406, 0.14883561,\n",
    "        0.14223936, 0.13812864, 0.13216646, 0.12886891, 0.12677656],\n",
    "       [0.5090754 , 0.36697951, 0.30763257, 0.27095798, 0.24148753,\n",
    "        0.22337331, 0.19389677, 0.17812392, 0.16715343, 0.15391363,\n",
    "        0.14001179, 0.13133219, 0.12238302, 0.11827273, 0.11173678]])\n",
    "Val0005 = np.array([[0.56371456, 0.39919326, 0.34435099, 0.304436  , 0.26631185,\n",
    "        0.23099618, 0.20328303, 0.18292068, 0.16978583, 0.15367405,\n",
    "        0.14461555, 0.13576211, 0.12829004, 0.1231632 , 0.11930799],\n",
    "       [0.55869371, 0.40093383, 0.34724513, 0.31373376, 0.28069019,\n",
    "        0.25570101, 0.23414214, 0.21497826, 0.19633742, 0.18155685,\n",
    "        0.17195155, 0.16187638, 0.15481564, 0.15380354, 0.14201556],\n",
    "       [0.5361256 , 0.38282689, 0.32527199, 0.28049859, 0.24196605,\n",
    "        0.21402383, 0.18566085, 0.17257425, 0.15611392, 0.14318419,\n",
    "        0.13591801, 0.13009866, 0.12409488, 0.11858173, 0.11509367],\n",
    "       [0.47310925, 0.31585214, 0.26405978, 0.23629363, 0.21481743,\n",
    "        0.1985812 , 0.18842463, 0.17883441, 0.16964333, 0.16689895,\n",
    "        0.16170117, 0.15715431, 0.15173787, 0.15018415, 0.14763325],\n",
    "       [0.52899235, 0.38816255, 0.32814357, 0.28632629, 0.25608152,\n",
    "        0.23640506, 0.20689945, 0.18967098, 0.17897335, 0.16758189,\n",
    "        0.15351024, 0.14587049, 0.13714264, 0.13190079, 0.12694463]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(1, 16)\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, sharex=True, sharey=True, figsize=(12, 6))\n",
    "\n",
    "\n",
    "ax0.plot(t, Tr005.mean(axis=0), lw=2, label='Train', color='blue')\n",
    "ax0.plot(t, Val005.mean(axis=0), lw=2, label='Val', color='red')\n",
    "ax0.fill_between(t, Tr005.mean(axis=0)+Tr005.std(axis=0), \n",
    "                 Tr005.mean(axis=0)-Tr005.std(axis=0), facecolor='blue', alpha=0.5)\n",
    "ax0.fill_between(t, Val005.mean(axis=0)+Val005.std(axis=0), \n",
    "                 Val005.mean(axis=0)-Val005.std(axis=0), facecolor='red', alpha=0.5)\n",
    "ax0.set_title('LR: 0.005')\n",
    "\n",
    "\n",
    "ax1.plot(t, Tr001.mean(axis=0), lw=2, label='Train', color='blue')\n",
    "ax1.plot(t, Val001.mean(axis=0), lw=2, label='Val', color='red')\n",
    "ax1.fill_between(t, Tr001.mean(axis=0)+Tr001.std(axis=0), \n",
    "                 Tr001.mean(axis=0)-Tr001.std(axis=0), facecolor='blue', alpha=0.5)\n",
    "ax1.fill_between(t, Val001.mean(axis=0)+Val001.std(axis=0), \n",
    "                 Val001.mean(axis=0)-Val001.std(axis=0), facecolor='red', alpha=0.5)\n",
    "ax1.set_title('LR: 0.001')\n",
    "\n",
    "\n",
    "\n",
    "ax2.plot(t, Tr0005.mean(axis=0), lw=2, label='Train', color='blue')\n",
    "ax2.plot(t, Val0005.mean(axis=0), lw=2, label='Val', color='red')\n",
    "ax2.fill_between(t, Tr0005.mean(axis=0)+Tr0005.std(axis=0), \n",
    "                 Tr0005.mean(axis=0)-Tr0005.std(axis=0), facecolor='blue', alpha=0.5)\n",
    "ax2.fill_between(t, Val0005.mean(axis=0)+Val0005.std(axis=0), \n",
    "                 Val0005.mean(axis=0)-Val0005.std(axis=0), facecolor='red', alpha=0.5)\n",
    "ax2.set_title('LR: 0.0005')\n",
    "\n",
    "ax2.legend(loc='upper right')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax0.set_ylabel('Negative Log Likelihood')\n",
    "ax0.grid()\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "\n",
    "fig.suptitle('Effect of Learning Rate on Training and Validation Loss')\n",
    "plt.savefig('Question 5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acc(loader):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "        \n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i, label in enumerate(labels):\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    print('Accuracy of the network: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net, criterion, optimizer, device = get_nn(learning_rate=0.005)\n",
    "trainloss, valloss = train(net, criterion, optimizer, device, epochs=15)\n",
    "evaluate_acc(trainloader)\n",
    "evaluate_acc(valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net, criterion, optimizer, device = get_nn(learning_rate=0.001)\n",
    "trainloss, valloss = train(net, criterion, optimizer, device, epochs=15)\n",
    "evaluate_acc(trainloader)\n",
    "evaluate_acc(valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net, criterion, optimizer, device = get_nn(learning_rate=0.0005)\n",
    "trainloss, valloss = train(net, criterion, optimizer, device, epochs=15)\n",
    "evaluate_acc(trainloader)\n",
    "evaluate_acc(valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del trainloader, valloader, testloader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "del trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net, criterion, optimizer, device = get_nn(learning_rate=0.001)\n",
    "trainloss = train(net, criterion, optimizer, device, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_acc(trainloader)\n",
    "evaluate_acc(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
